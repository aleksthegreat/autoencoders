{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wopr/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py:265: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/wopr/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bernoulli.py:169: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add,PReLU, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import tensorflow as tf\n",
    "import horovod.keras as hvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce memory\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 78.01 MB\n",
      "Decreased by 74.7%\n",
      "Memory usage after optimization is: 77.82 MB\n",
      "Decreased by 74.6%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(pd.read_csv('../input/train.csv'))\n",
    "test = reduce_mem_usage(pd.read_csv('../input/test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in train if f not in ['ID_code','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.concat([train, test],axis=0,sort=False)\n",
    "df = df_original[features]\n",
    "target = df_original['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for feature in features:\n",
    "#    df['mean_'+feature] = (train[feature].mean()-train[feature])\n",
    "#    df['z_'+feature] = (train[feature] - train[feature].mean())/train[feature].std(ddof=0)\n",
    "#    df['sq_'+feature] = (train[feature])**2\n",
    "#    df['sqrt_'+feature] = np.abs(train[feature])**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/pandas/core/indexing.py:630: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "for df in [df]:\n",
    "#####Handling Missing Values#####     \n",
    "    for i in range(len(df.columns)):\n",
    "        df.iloc[:,i] = (df.iloc[:,i]).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import erfinv\n",
    "\n",
    "trafo_columns = [c for c in df.columns if len(df[c].unique()) != 2]\n",
    "for col in trafo_columns:\n",
    "    values = sorted(set(df[col]))\n",
    "    # Because erfinv(1) is inf, we shrink the range into (-0.9, 0.9)\n",
    "    f = pd.Series(np.linspace(-0.9, 0.9, len(values)), index=values)\n",
    "    f = np.sqrt(2) * erfinv(f)\n",
    "    f -= f.mean()\n",
    "    df[col] = df[col].map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(df[trafo_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.276234</td>\n",
       "      <td>-1.248264</td>\n",
       "      <td>0.492790</td>\n",
       "      <td>0.178309</td>\n",
       "      <td>0.301589</td>\n",
       "      <td>-1.103686</td>\n",
       "      <td>0.089022</td>\n",
       "      <td>0.470353</td>\n",
       "      <td>-1.241425</td>\n",
       "      <td>-0.489018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264992</td>\n",
       "      <td>1.095784</td>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.287438</td>\n",
       "      <td>-1.189143</td>\n",
       "      <td>1.255593</td>\n",
       "      <td>0.127525</td>\n",
       "      <td>-0.142190</td>\n",
       "      <td>-0.439702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544823</td>\n",
       "      <td>-1.053062</td>\n",
       "      <td>0.787904</td>\n",
       "      <td>0.232411</td>\n",
       "      <td>0.491863</td>\n",
       "      <td>1.179872</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.289916</td>\n",
       "      <td>1.054877</td>\n",
       "      <td>0.565805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720530</td>\n",
       "      <td>1.007539</td>\n",
       "      <td>1.377199</td>\n",
       "      <td>-0.075167</td>\n",
       "      <td>1.229373</td>\n",
       "      <td>1.270814</td>\n",
       "      <td>0.197394</td>\n",
       "      <td>0.609579</td>\n",
       "      <td>0.682261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.245349</td>\n",
       "      <td>-0.890334</td>\n",
       "      <td>0.516770</td>\n",
       "      <td>0.739213</td>\n",
       "      <td>0.126346</td>\n",
       "      <td>-1.097304</td>\n",
       "      <td>0.821339</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>-1.241094</td>\n",
       "      <td>-0.389013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892009</td>\n",
       "      <td>0.833005</td>\n",
       "      <td>0.689442</td>\n",
       "      <td>0.625478</td>\n",
       "      <td>1.481717</td>\n",
       "      <td>-1.262358</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>0.174366</td>\n",
       "      <td>0.313988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.496957</td>\n",
       "      <td>-0.824797</td>\n",
       "      <td>0.111059</td>\n",
       "      <td>0.583860</td>\n",
       "      <td>0.542499</td>\n",
       "      <td>-0.621498</td>\n",
       "      <td>0.354577</td>\n",
       "      <td>0.070753</td>\n",
       "      <td>-1.325206</td>\n",
       "      <td>0.606487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355110</td>\n",
       "      <td>0.545014</td>\n",
       "      <td>0.639970</td>\n",
       "      <td>0.805761</td>\n",
       "      <td>-0.897988</td>\n",
       "      <td>-0.942853</td>\n",
       "      <td>0.707354</td>\n",
       "      <td>0.571748</td>\n",
       "      <td>-0.994165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.368229</td>\n",
       "      <td>-0.703462</td>\n",
       "      <td>0.632252</td>\n",
       "      <td>0.469332</td>\n",
       "      <td>0.472988</td>\n",
       "      <td>0.818812</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.527034</td>\n",
       "      <td>1.381489</td>\n",
       "      <td>0.387166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871307</td>\n",
       "      <td>-0.407311</td>\n",
       "      <td>1.296442</td>\n",
       "      <td>-0.517185</td>\n",
       "      <td>-0.965731</td>\n",
       "      <td>0.975661</td>\n",
       "      <td>0.424890</td>\n",
       "      <td>0.574743</td>\n",
       "      <td>-0.988783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "0  0.276234 -1.248264  0.492790  0.178309  0.301589 -1.103686  0.089022   \n",
       "1  0.544823 -1.053062  0.787904  0.232411  0.491863  1.179872  0.271400   \n",
       "2  0.245349 -0.890334  0.516770  0.739213  0.126346 -1.097304  0.821339   \n",
       "3  0.496957 -0.824797  0.111059  0.583860  0.542499 -0.621498  0.354577   \n",
       "4  0.368229 -0.703462  0.632252  0.469332  0.472988  0.818812  0.391812   \n",
       "\n",
       "      var_7     var_8     var_9   ...     var_191   var_192   var_193  \\\n",
       "0  0.470353 -1.241425 -0.489018   ...    0.264992  1.095784  0.690561   \n",
       "1  0.289916  1.054877  0.565805   ...    0.720530  1.007539  1.377199   \n",
       "2  0.021898 -1.241094 -0.389013   ...    0.892009  0.833005  0.689442   \n",
       "3  0.070753 -1.325206  0.606487   ...    0.355110  0.545014  0.639970   \n",
       "4  0.527034  1.381489  0.387166   ...    0.871307 -0.407311  1.296442   \n",
       "\n",
       "    var_194   var_195   var_196   var_197   var_198   var_199  target  \n",
       "0  0.287438 -1.189143  1.255593  0.127525 -0.142190 -0.439702     0.0  \n",
       "1 -0.075167  1.229373  1.270814  0.197394  0.609579  0.682261     0.0  \n",
       "2  0.625478  1.481717 -1.262358  0.036855  0.174366  0.313988     0.0  \n",
       "3  0.805761 -0.897988 -0.942853  0.707354  0.571748 -0.994165     0.0  \n",
       "4 -0.517185 -0.965731  0.975661  0.424890  0.574743 -0.988783     0.0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = df_original['target']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 156.40 MB\n",
      "Decreased by 74.6%\n"
     ]
    }
   ],
   "source": [
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "/home/wopr/.local/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    }
   ],
   "source": [
    "train = df[df['target'].notnull()]\n",
    "target = train['target']\n",
    "train = pd.DataFrame(pca.transform(train[trafo_columns]))\n",
    "test = df[df['target'].isnull()]\n",
    "test = pd.DataFrame(pca.transform(test[trafo_columns]))\n",
    "train.shape\n",
    "\n",
    "trafo_columns = [c for c in train.columns if len(train[c].unique()) != 2]\n",
    "train['target'] = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Before OverSampling, counts of label 0.0: 119934\n",
      "Before OverSampling, counts of label 1.0: 13398\n",
      "After OverSampling, the shape of train_X: (239868, 100)\n",
      "After OverSampling, the shape of train_y: (239868,) \n",
      "\n",
      "After OverSampling, counts of label 0.0: 119934\n",
      "After OverSampling, counts of label 1.0: 119934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "999/999 [==============================] - 59s 59ms/step - loss: 800.0950 - acc: 0.0062 - val_loss: 253.7975 - val_acc: 0.0097\n",
      "Epoch 2/2\n",
      "999/999 [==============================] - 61s 61ms/step - loss: 797.1954 - acc: 0.0060 - val_loss: 253.7095 - val_acc: 0.0092\n",
      "66668/66668 [==============================] - 7s 104us/step\n",
      "200000/200000 [==============================] - 21s 105us/step\n",
      "200000/200000 [==============================] - 21s 103us/step\n",
      "fold 1\n",
      "Before OverSampling, counts of label 0.0: 119935\n",
      "Before OverSampling, counts of label 1.0: 13399\n",
      "After OverSampling, the shape of train_X: (239870, 100)\n",
      "After OverSampling, the shape of train_y: (239870,) \n",
      "\n",
      "After OverSampling, counts of label 0.0: 119935\n",
      "After OverSampling, counts of label 1.0: 119935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "999/999 [==============================] - 62s 62ms/step - loss: 800.1234 - acc: 0.0059 - val_loss: 253.7166 - val_acc: 0.0112\n",
      "Epoch 2/2\n",
      "999/999 [==============================] - 64s 64ms/step - loss: 797.1945 - acc: 0.0056 - val_loss: 253.6390 - val_acc: 0.0116\n",
      "66666/66666 [==============================] - 7s 104us/step\n",
      "200000/200000 [==============================] - 21s 105us/step\n",
      "200000/200000 [==============================] - 21s 104us/step\n",
      "fold 2\n",
      "Before OverSampling, counts of label 0.0: 119935\n",
      "Before OverSampling, counts of label 1.0: 13399\n",
      "After OverSampling, the shape of train_X: (239870, 100)\n",
      "After OverSampling, the shape of train_y: (239870,) \n",
      "\n",
      "After OverSampling, counts of label 0.0: 119935\n",
      "After OverSampling, counts of label 1.0: 119935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "999/999 [==============================] - 62s 63ms/step - loss: 800.0490 - acc: 9.7181e-04 - val_loss: 253.7501 - val_acc: 0.0117\n",
      "Epoch 2/2\n",
      "999/999 [==============================] - 64s 64ms/step - loss: 797.2724 - acc: 0.0010 - val_loss: 253.6778 - val_acc: 0.0120\n",
      "66666/66666 [==============================] - 7s 107us/step\n",
      "200000/200000 [==============================] - 21s 105us/step\n",
      "200000/200000 [==============================] - 21s 103us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction_error</th>\n",
       "      <th>True_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.955704</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.230667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.127419</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.795946</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.945383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.105156</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.225054</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction_error  True_class\n",
       "count         200000.000000    200000.0\n",
       "mean               1.955704         0.0\n",
       "std                0.230667         0.0\n",
       "min                1.127419         0.0\n",
       "25%                1.795946         0.0\n",
       "50%                1.945383         0.0\n",
       "75%                2.105156         0.0\n",
       "max                3.225054         1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.activations import elu\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from imblearn.keras import balanced_batch_generator\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler, CondensedNearestNeighbour, AllKNN\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Horovod: adjust learning rate based on number of GPUs.\n",
    "opt = keras.optimizers.SGD(lr=0.00001, decay=0.96, momentum=0.001, nesterov=True)\n",
    "# Horovod: add Horovod Distributed Optimizer.\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "\n",
    "\n",
    "nb_folds = 3\n",
    "nb_epoch = 2\n",
    "batch_size = 240\n",
    "encoding_dim =1000\n",
    "hidden_dim = int(encoding_dim * 10) #i.e. 7\n",
    "sgd = SGD(lr=0.001, momentum=0.001, decay=0.96)\n",
    "folds = StratifiedKFold(n_splits=nb_folds, shuffle=True, random_state=420)\n",
    "#folds = KFold(n_splits = nb_folds, random_state = 338, shuffle = True)\n",
    "train_auto = np.zeros(train[trafo_columns].shape)\n",
    "test_auto = np.zeros(test[trafo_columns].shape)\n",
    "predictions = np.zeros(len(train))\n",
    "label_cols = [\"target\"]\n",
    "y_split = train[label_cols].values\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_0.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "es= EarlyStopping(monitor='val_loss',\n",
    "                  min_delta=0,\n",
    "                  patience=50,\n",
    "                  verbose=1, mode='auto')\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(y_split[:,0], y_split[:,0])):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "#for fold_, (trn_idx, val_idx) in enumerate(folds.split(train)):\n",
    "#    print(\"fold {}\".format(fold_))\n",
    "\n",
    "    trn_data, trn_y = train[trafo_columns].iloc[trn_idx], train['target'].iloc[trn_idx]\n",
    "    val_data, val_y = train[trafo_columns].iloc[val_idx], train['target'].iloc[val_idx]\n",
    "\n",
    "    \n",
    "    \n",
    "    classes=[]\n",
    "    for i in np.unique(trn_y):\n",
    "        classes.append(i)\n",
    "        print(\"Before OverSampling, counts of label \" + str(i) + \": {}\".format(sum(trn_y==i)))\n",
    "\n",
    "    sm=SMOTE(random_state=2)\n",
    "    trn_data, train_y = sm.fit_sample(trn_data, trn_y.ravel())\n",
    "\n",
    "    print('After OverSampling, the shape of train_X: {}'.format(trn_data.shape))\n",
    "    print('After OverSampling, the shape of train_y: {} \\n'.format(train_y.shape))\n",
    "\n",
    "    for eachClass in classes:\n",
    "        print(\"After OverSampling, counts of label \" + str(eachClass) + \": {}\".format(sum(train_y==eachClass)))\n",
    "\n",
    "    input_dim = trn_data.shape[1] #num of columns, 30\n",
    "    input_layer = Input(shape=(input_dim, ))\n",
    "    \n",
    "    # Q(z|X) -- encoder\n",
    "    h_q = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    mu = Dense(hidden_dim, activation='linear')(h_q)\n",
    "    log_sigma = Dense(hidden_dim, activation='linear')(h_q)\n",
    "    \n",
    "    def sample_z(args):\n",
    "        mu, log_sigma = args\n",
    "        batch = K.shape(mu)[0]\n",
    "        dim = K.int_shape(mu)[1]\n",
    "        eps = K.random_normal(shape=(batch, dim))\n",
    "        return mu + K.exp(0.5 * log_sigma) * eps\n",
    "\n",
    "    # Sample z ~ Q(z|X)\n",
    "    z = Lambda(sample_z)([mu, log_sigma])\n",
    "    \n",
    "    # P(X|z) -- decoder\n",
    "    decoder_hidden = Dense(hidden_dim, activation='relu')\n",
    "    decoder_out = Dense(input_dim, activation='softmax')\n",
    "    h_p = decoder_hidden(z)\n",
    "    outputs = decoder_out(h_p)\n",
    "    \n",
    "    # Overall VAE model, for reconstruction and training\n",
    "    vae = Model(input_layer, outputs)\n",
    "    \n",
    "    # Encoder model, to encode input into latent variable\n",
    "    # We use the mean as the output as it is the center point, the representative of the gaussian\n",
    "    encoder = Model(input_layer, mu)\n",
    "\n",
    "    # Generator model, generate new data given latent variable z\n",
    "    d_in = Input(shape=(hidden_dim,))\n",
    "    d_h = decoder_hidden(d_in)\n",
    "    d_out = decoder_out(d_h)\n",
    "    decoder = Model(d_in, d_out)\n",
    "    \n",
    "    def vae_loss(y_true, y_pred):\n",
    "        \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
    "        # E[log P(X|z)]\n",
    "        recon = K.sum(K.binary_crossentropy(y_pred, y_true), axis=1)\n",
    "        # D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
    "        kl = 0.5 * K.sum(K.exp(log_sigma) + K.square(mu) - 1. - log_sigma, axis=1)\n",
    "        return recon + kl\n",
    "    \n",
    "    vae.compile(optimizer='sgd', loss=vae_loss, metrics=['acc'])\n",
    "    \n",
    "    def add_noise(series, noise_level):\n",
    "        return series * (1 + noise_level * np.random.randn(series.shape[1]))\n",
    "    \n",
    "    trn_data = add_noise(trn_data, 0.05)\n",
    "#    val_data = add_noise(val_data, 0.07)\n",
    "    \n",
    "\n",
    "    training_generator, steps_per_epoch = balanced_batch_generator(trn_data, train_y, sampler=RandomOverSampler(),\n",
    "                                                batch_size=batch_size, random_state=42)\n",
    "\n",
    "    callback_history = vae.fit_generator(training_generator,epochs=nb_epoch,\n",
    "                       validation_data=[val_data, val_data], \n",
    "                       steps_per_epoch=steps_per_epoch, verbose=1,\n",
    "                       callbacks=[cp, tb, es])\n",
    "\n",
    "    train_auto[val_idx] += vae.predict(train.iloc[val_idx][trafo_columns], verbose=1)\n",
    "    test_auto += vae.predict(test[trafo_columns], verbose=1)\n",
    "\n",
    "    mse = vae.predict(train[trafo_columns] / folds.n_splits, verbose=1)\n",
    "    predictions += np.mean(np.power(train[trafo_columns] - mse, 2), axis=1)\n",
    "\n",
    "train_auto = pd.DataFrame(train_auto / folds.n_splits)\n",
    "test_auto = pd.DataFrame(test_auto / folds.n_splits)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': predictions,\n",
    "                        'True_class': train['target']})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####Edit thiS!!!!!####\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LABELS = [\"Normal\",\"outlier\"]\n",
    "threshold_fixed = 2.805156\n",
    "pred_y = [1 if e > threshold_fixed else 0 for e in error_df.Reconstruction_error.values]\n",
    "conf_matrix = confusion_matrix(train['target'], pred_y)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = df_original[df_original['target'].notnull()]\n",
    "test_id = df_original[df_original['target'].isnull()]\n",
    "\n",
    "train_auto['target'] = target\n",
    "train_auto['id'] = train_id['ID_code']\n",
    "test_auto['id'] = test_id['ID_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_auto.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [trn_data, val_data, df_original, train]\n",
    "del trn_data, val_data, df_original, train\n",
    "del lst     # memory is released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_original['auto_mse_lvl_0'] = error_df.Reconstruction_error.values\n",
    "#bcvdf_original['classlvl_0'] = [1 if e > threshold_fixed else 0 for e in df_original.auto_mse_lvl_0.values]\n",
    "#df_original.head(5)bcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_original.to_csv(\"df_original.csv\", index=False)\n",
    "train_auto.to_csv(\"auto_model_reconstructions/train_auto_0.csv\", index=False)\n",
    "test_auto.to_csv(\"auto_model_reconstructions/test_auto_0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
