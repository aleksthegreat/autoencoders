{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wopr/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/distribution.py:265: ReparameterizationType.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /home/wopr/.local/lib/python3.6/site-packages/tensorflow/python/ops/distributions/bernoulli.py:169: RegisterKL.__init__ (from tensorflow.python.ops.distributions.kullback_leibler) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add,PReLU, LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import tensorflow as tf\n",
    "import horovod.keras as hvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce memory\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 78.01 MB\n",
      "Decreased by 74.7%\n",
      "Memory usage after optimization is: 77.82 MB\n",
      "Decreased by 74.6%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(pd.read_csv('../input/train.csv'))\n",
    "test = reduce_mem_usage(pd.read_csv('../input/test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [f for f in train if f not in ['ID_code','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.concat([train, test],axis=0,sort=False)\n",
    "df = df_original[features]\n",
    "target = df_original['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for feature in features:\n",
    "#    df['mean_'+feature] = (train[feature].mean()-train[feature])\n",
    "#    df['z_'+feature] = (train[feature] - train[feature].mean())/train[feature].std(ddof=0)\n",
    "#    df['sq_'+feature] = (train[feature])**2\n",
    "#    df['sqrt_'+feature] = np.abs(train[feature])**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/pandas/core/indexing.py:630: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "for df in [df]:\n",
    "#####Handling Missing Values#####     \n",
    "    for i in range(len(df.columns)):\n",
    "        df.iloc[:,i] = (df.iloc[:,i]).fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import erfinv\n",
    "\n",
    "trafo_columns = [c for c in df.columns if len(df[c].unique()) != 2]\n",
    "for col in trafo_columns:\n",
    "    values = sorted(set(df[col]))\n",
    "    # Because erfinv(1) is inf, we shrink the range into (-0.9, 0.9)\n",
    "    f = pd.Series(np.linspace(-0.9, 0.9, len(values)), index=values)\n",
    "    f = np.sqrt(2) * erfinv(f)\n",
    "    f -= f.mean()\n",
    "    df[col] = df[col].map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=100, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=100)\n",
    "pca.fit(df[trafo_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.276234</td>\n",
       "      <td>-1.248264</td>\n",
       "      <td>0.492790</td>\n",
       "      <td>0.178309</td>\n",
       "      <td>0.301589</td>\n",
       "      <td>-1.103686</td>\n",
       "      <td>0.089022</td>\n",
       "      <td>0.470353</td>\n",
       "      <td>-1.241425</td>\n",
       "      <td>-0.489018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264992</td>\n",
       "      <td>1.095784</td>\n",
       "      <td>0.690561</td>\n",
       "      <td>0.287438</td>\n",
       "      <td>-1.189143</td>\n",
       "      <td>1.255593</td>\n",
       "      <td>0.127525</td>\n",
       "      <td>-0.142190</td>\n",
       "      <td>-0.439702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544823</td>\n",
       "      <td>-1.053062</td>\n",
       "      <td>0.787904</td>\n",
       "      <td>0.232411</td>\n",
       "      <td>0.491863</td>\n",
       "      <td>1.179872</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>0.289916</td>\n",
       "      <td>1.054877</td>\n",
       "      <td>0.565805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720530</td>\n",
       "      <td>1.007539</td>\n",
       "      <td>1.377199</td>\n",
       "      <td>-0.075167</td>\n",
       "      <td>1.229373</td>\n",
       "      <td>1.270814</td>\n",
       "      <td>0.197394</td>\n",
       "      <td>0.609579</td>\n",
       "      <td>0.682261</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.245349</td>\n",
       "      <td>-0.890334</td>\n",
       "      <td>0.516770</td>\n",
       "      <td>0.739213</td>\n",
       "      <td>0.126346</td>\n",
       "      <td>-1.097304</td>\n",
       "      <td>0.821339</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>-1.241094</td>\n",
       "      <td>-0.389013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.892009</td>\n",
       "      <td>0.833005</td>\n",
       "      <td>0.689442</td>\n",
       "      <td>0.625478</td>\n",
       "      <td>1.481717</td>\n",
       "      <td>-1.262358</td>\n",
       "      <td>0.036855</td>\n",
       "      <td>0.174366</td>\n",
       "      <td>0.313988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.496957</td>\n",
       "      <td>-0.824797</td>\n",
       "      <td>0.111059</td>\n",
       "      <td>0.583860</td>\n",
       "      <td>0.542499</td>\n",
       "      <td>-0.621498</td>\n",
       "      <td>0.354577</td>\n",
       "      <td>0.070753</td>\n",
       "      <td>-1.325206</td>\n",
       "      <td>0.606487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355110</td>\n",
       "      <td>0.545014</td>\n",
       "      <td>0.639970</td>\n",
       "      <td>0.805761</td>\n",
       "      <td>-0.897988</td>\n",
       "      <td>-0.942853</td>\n",
       "      <td>0.707354</td>\n",
       "      <td>0.571748</td>\n",
       "      <td>-0.994165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.368229</td>\n",
       "      <td>-0.703462</td>\n",
       "      <td>0.632252</td>\n",
       "      <td>0.469332</td>\n",
       "      <td>0.472988</td>\n",
       "      <td>0.818812</td>\n",
       "      <td>0.391812</td>\n",
       "      <td>0.527034</td>\n",
       "      <td>1.381489</td>\n",
       "      <td>0.387166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871307</td>\n",
       "      <td>-0.407311</td>\n",
       "      <td>1.296442</td>\n",
       "      <td>-0.517185</td>\n",
       "      <td>-0.965731</td>\n",
       "      <td>0.975661</td>\n",
       "      <td>0.424890</td>\n",
       "      <td>0.574743</td>\n",
       "      <td>-0.988783</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var_0     var_1     var_2     var_3     var_4     var_5     var_6  \\\n",
       "0  0.276234 -1.248264  0.492790  0.178309  0.301589 -1.103686  0.089022   \n",
       "1  0.544823 -1.053062  0.787904  0.232411  0.491863  1.179872  0.271400   \n",
       "2  0.245349 -0.890334  0.516770  0.739213  0.126346 -1.097304  0.821339   \n",
       "3  0.496957 -0.824797  0.111059  0.583860  0.542499 -0.621498  0.354577   \n",
       "4  0.368229 -0.703462  0.632252  0.469332  0.472988  0.818812  0.391812   \n",
       "\n",
       "      var_7     var_8     var_9   ...     var_191   var_192   var_193  \\\n",
       "0  0.470353 -1.241425 -0.489018   ...    0.264992  1.095784  0.690561   \n",
       "1  0.289916  1.054877  0.565805   ...    0.720530  1.007539  1.377199   \n",
       "2  0.021898 -1.241094 -0.389013   ...    0.892009  0.833005  0.689442   \n",
       "3  0.070753 -1.325206  0.606487   ...    0.355110  0.545014  0.639970   \n",
       "4  0.527034  1.381489  0.387166   ...    0.871307 -0.407311  1.296442   \n",
       "\n",
       "    var_194   var_195   var_196   var_197   var_198   var_199  target  \n",
       "0  0.287438 -1.189143  1.255593  0.127525 -0.142190 -0.439702     0.0  \n",
       "1 -0.075167  1.229373  1.270814  0.197394  0.609579  0.682261     0.0  \n",
       "2  0.625478  1.481717 -1.262358  0.036855  0.174366  0.313988     0.0  \n",
       "3  0.805761 -0.897988 -0.942853  0.707354  0.571748 -0.994165     0.0  \n",
       "4 -0.517185 -0.965731  0.975661  0.424890  0.574743 -0.988783     0.0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = df_original['target']\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 156.40 MB\n",
      "Decreased by 74.6%\n"
     ]
    }
   ],
   "source": [
    "df = reduce_mem_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wopr/.local/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "/home/wopr/.local/lib/python3.6/site-packages/numpy/core/_methods.py:36: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n"
     ]
    }
   ],
   "source": [
    "train = df[df['target'].notnull()]\n",
    "target = train['target']\n",
    "train = pd.DataFrame(pca.transform(train[trafo_columns]))\n",
    "test = df[df['target'].isnull()]\n",
    "test = pd.DataFrame(pca.transform(test[trafo_columns]))\n",
    "train.shape\n",
    "\n",
    "trafo_columns = [c for c in train.columns if len(train[c].unique()) != 2]\n",
    "train['target'] = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Epoch 1/2\n",
      "999/999 [==============================] - 61s 61ms/step - loss: 800.1196 - acc: 0.0025 - val_loss: 253.6297 - val_acc: 0.0085\n",
      "Epoch 2/2\n",
      "999/999 [==============================] - 64s 64ms/step - loss: 797.2656 - acc: 0.0026 - val_loss: 253.5793 - val_acc: 0.0090\n",
      "66668/66668 [==============================] - 8s 116us/step\n",
      "200000/200000 [==============================] - 22s 111us/step\n",
      "200000/200000 [==============================] - 22s 109us/step\n",
      "fold 1\n",
      "Epoch 1/2\n",
      "999/999 [==============================] - 65s 65ms/step - loss: 800.1594 - acc: 0.0639 - val_loss: 253.2430 - val_acc: 0.0082\n",
      "Epoch 2/2\n",
      "999/999 [==============================] - 65s 65ms/step - loss: 797.2316 - acc: 0.0647 - val_loss: 253.1972 - val_acc: 0.0079\n",
      "66666/66666 [==============================] - 8s 113us/step\n",
      "200000/200000 [==============================] - 22s 110us/step\n",
      "200000/200000 [==============================] - 22s 111us/step\n",
      "fold 2\n",
      "Epoch 1/2\n",
      "999/999 [==============================] - 65s 65ms/step - loss: 800.1802 - acc: 0.0012 - val_loss: 253.3920 - val_acc: 0.0076\n",
      "Epoch 2/2\n",
      "999/999 [==============================] - 65s 65ms/step - loss: 797.2707 - acc: 0.0013 - val_loss: 253.3341 - val_acc: 0.0081\n",
      "66666/66666 [==============================] - 7s 112us/step\n",
      "200000/200000 [==============================] - 22s 111us/step\n",
      "200000/200000 [==============================] - 22s 111us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reconstruction_error</th>\n",
       "      <th>True_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.956053</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.231028</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.133084</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.796056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.945483</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.105687</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.216720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reconstruction_error  True_class\n",
       "count         200000.000000    200000.0\n",
       "mean               1.956053         0.0\n",
       "std                0.231028         0.0\n",
       "min                1.133084         0.0\n",
       "25%                1.796056         0.0\n",
       "50%                1.945483         0.0\n",
       "75%                2.105687         0.0\n",
       "max                3.216720         1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.activations import elu\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from imblearn.keras import balanced_batch_generator\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler, CondensedNearestNeighbour, AllKNN\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# Horovod: adjust learning rate based on number of GPUs.\n",
    "opt = keras.optimizers.SGD(lr=0.00001, decay=0.96, momentum=0.001, nesterov=True)\n",
    "# Horovod: add Horovod Distributed Optimizer.\n",
    "opt = hvd.DistributedOptimizer(opt)\n",
    "\n",
    "\n",
    "nb_folds = 3\n",
    "nb_epoch = 2\n",
    "batch_size = 240\n",
    "encoding_dim =1000\n",
    "hidden_dim = int(encoding_dim * 10) #i.e. 7\n",
    "sgd = SGD(lr=0.001, momentum=0.001, decay=0.96)\n",
    "folds = StratifiedKFold(n_splits=nb_folds, shuffle=True, random_state=420)\n",
    "#folds = KFold(n_splits = nb_folds, random_state = 338, shuffle = True)\n",
    "train_auto = np.zeros(train[trafo_columns].shape)\n",
    "test_auto = np.zeros(test[trafo_columns].shape)\n",
    "predictions = np.zeros(len(train))\n",
    "label_cols = [\"target\"]\n",
    "y_split = train[label_cols].values\n",
    "\n",
    "cp = ModelCheckpoint(filepath=\"autoencoder_0.h5\",\n",
    "                               save_best_only=True,\n",
    "                               verbose=0)\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',\n",
    "                histogram_freq=0,\n",
    "                write_graph=True,\n",
    "                write_images=True)\n",
    "\n",
    "es= EarlyStopping(monitor='val_loss',\n",
    "                  min_delta=0,\n",
    "                  patience=50,\n",
    "                  verbose=1, mode='auto')\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(y_split[:,0], y_split[:,0])):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "#for fold_, (trn_idx, val_idx) in enumerate(folds.split(train)):\n",
    "#    print(\"fold {}\".format(fold_))\n",
    "\n",
    "    trn_data, train_y = train[trafo_columns].iloc[trn_idx], train['target'].iloc[trn_idx]\n",
    "    val_data, valid_y = train[trafo_columns].iloc[val_idx], train['target'].iloc[val_idx]\n",
    "\n",
    "    input_dim = trn_data.shape[1] #num of columns, 30\n",
    "    input_layer = Input(shape=(input_dim, ))\n",
    "    \n",
    "    # Q(z|X) -- encoder\n",
    "    h_q = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "    mu = Dense(hidden_dim, activation='linear')(h_q)\n",
    "    log_sigma = Dense(hidden_dim, activation='linear')(h_q)\n",
    "    \n",
    "    def sample_z(args):\n",
    "        mu, log_sigma = args\n",
    "        batch = K.shape(mu)[0]\n",
    "        dim = K.int_shape(mu)[1]\n",
    "        eps = K.random_normal(shape=(batch, dim))\n",
    "        return mu + K.exp(0.5 * log_sigma) * eps\n",
    "\n",
    "    # Sample z ~ Q(z|X)\n",
    "    z = Lambda(sample_z)([mu, log_sigma])\n",
    "    \n",
    "    # P(X|z) -- decoder\n",
    "    decoder_hidden = Dense(hidden_dim, activation='relu')\n",
    "    decoder_out = Dense(input_dim, activation='softmax')\n",
    "    h_p = decoder_hidden(z)\n",
    "    outputs = decoder_out(h_p)\n",
    "    \n",
    "    # Overall VAE model, for reconstruction and training\n",
    "    vae = Model(input_layer, outputs)\n",
    "    \n",
    "    # Encoder model, to encode input into latent variable\n",
    "    # We use the mean as the output as it is the center point, the representative of the gaussian\n",
    "    encoder = Model(input_layer, mu)\n",
    "\n",
    "    # Generator model, generate new data given latent variable z\n",
    "    d_in = Input(shape=(hidden_dim,))\n",
    "    d_h = decoder_hidden(d_in)\n",
    "    d_out = decoder_out(d_h)\n",
    "    decoder = Model(d_in, d_out)\n",
    "    \n",
    "    def vae_loss(y_true, y_pred):\n",
    "        \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n",
    "        # E[log P(X|z)]\n",
    "        recon = K.sum(K.binary_crossentropy(y_pred, y_true), axis=1)\n",
    "        # D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian\n",
    "        kl = 0.5 * K.sum(K.exp(log_sigma) + K.square(mu) - 1. - log_sigma, axis=1)\n",
    "        return recon + kl\n",
    "    \n",
    "    vae.compile(optimizer='sgd', loss=vae_loss, metrics=['acc'])\n",
    "    \n",
    "    def add_noise(series, noise_level):\n",
    "        return series * (1 + noise_level * np.random.randn(series.shape[1]))\n",
    "    \n",
    "    trn_data = add_noise(trn_data, 0.05)\n",
    "#    val_data = add_noise(val_data, 0.07)\n",
    "    \n",
    "\n",
    "    training_generator, steps_per_epoch = balanced_batch_generator(trn_data, train_y, sampler=RandomOverSampler(),\n",
    "                                                batch_size=batch_size, random_state=42)\n",
    "\n",
    "    callback_history = vae.fit_generator(training_generator,epochs=nb_epoch,\n",
    "                       validation_data=[val_data, val_data], \n",
    "                       steps_per_epoch=steps_per_epoch, verbose=1,\n",
    "                       callbacks=[cp, tb, es])\n",
    "\n",
    "    train_auto[val_idx] += vae.predict(train.iloc[val_idx][trafo_columns], verbose=1)\n",
    "    test_auto += vae.predict(test[trafo_columns], verbose=1)\n",
    "\n",
    "    mse = vae.predict(train[trafo_columns] / folds.n_splits, verbose=1)\n",
    "    predictions += np.mean(np.power(train[trafo_columns] - mse, 2), axis=1)\n",
    "\n",
    "train_auto = pd.DataFrame(train_auto / folds.n_splits)\n",
    "test_auto = pd.DataFrame(test_auto / folds.n_splits)\n",
    "error_df = pd.DataFrame({'Reconstruction_error': predictions,\n",
    "                        'True_class': train['target']})\n",
    "error_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####Edit thiS!!!!!####\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LABELS = [\"Normal\",\"outlier\"]\n",
    "threshold_fixed = 2.105687\n",
    "pred_y = [1 if e > threshold_fixed else 0 for e in error_df.Reconstruction_error.values]\n",
    "conf_matrix = confusion_matrix(train['target'], pred_y)\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id = df_original[df_original['target'].notnull()]\n",
    "test_id = df_original[df_original['target'].isnull()]\n",
    "\n",
    "train_auto['target'] = target\n",
    "train_auto['id'] = train_id['ID_code']\n",
    "test_auto['id'] = test_id['ID_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.001437</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002907</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0.006924</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.020693</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.011132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.002153</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.011910</td>\n",
       "      <td>0.001083</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.008114</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.009704</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.002227  0.001164  0.005570  0.000704  0.000640  0.000461  0.001963   \n",
       "1  0.002907  0.003055  0.007179  0.001255  0.001825  0.001582  0.002146   \n",
       "2  0.003821  0.003746  0.002011  0.003343  0.010168  0.000604  0.000611   \n",
       "3  0.003260  0.000733  0.003551  0.000739  0.002255  0.002811  0.000354   \n",
       "4  0.013083  0.000722  0.020825  0.011910  0.001083  0.001033  0.002588   \n",
       "\n",
       "          7         8         9   ...           92        93        94  \\\n",
       "0  0.000730  0.004098  0.003401   ...     0.000574  0.004162  0.000409   \n",
       "1  0.002056  0.001749  0.002990   ...     0.000367  0.003391  0.001873   \n",
       "2  0.003293  0.002589  0.003075   ...     0.006187  0.003842  0.001869   \n",
       "3  0.001479  0.002153  0.000941   ...     0.000910  0.001169  0.000805   \n",
       "4  0.001583  0.001805  0.000956   ...     0.008724  0.002281  0.008114   \n",
       "\n",
       "         95        96        97        98        99  target       id  \n",
       "0  0.001437  0.002250  0.003215  0.001601  0.004311     0.0  train_0  \n",
       "1  0.002375  0.006924  0.001022  0.018457  0.002395     0.0  train_1  \n",
       "2  0.020693  0.002273  0.001177  0.002150  0.011132     0.0  train_2  \n",
       "3  0.000495  0.001376  0.003231  0.000609  0.000326     0.0  train_3  \n",
       "4  0.001016  0.000351  0.001530  0.009704  0.001803     0.0  train_4  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_auto.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [trn_data, val_data, df_original, train]\n",
    "del trn_data, val_data, df_original, train\n",
    "del lst     # memory is released"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_original['auto_mse_lvl_0'] = error_df.Reconstruction_error.values\n",
    "#bcvdf_original['classlvl_0'] = [1 if e > threshold_fixed else 0 for e in df_original.auto_mse_lvl_0.values]\n",
    "#df_original.head(5)bcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_original.to_csv(\"df_original.csv\", index=False)\n",
    "train_auto.to_csv(\"auto_model_reconstructions/train_auto_0.csv\", index=False)\n",
    "test_auto.to_csv(\"auto_model_reconstructions/test_auto_0.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
